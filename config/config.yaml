# config/config.yaml

# =====================================================================
# Intelligent Demand Sensing & Autonomous Inventory Planning (IDS)
# =====================================================================
# This configuration file is the SINGLE SOURCE OF TRUTH.
# All pipelines (ingestion → features → training → forecasting → inventory → LLM)
# must strictly follow this structure.
#
# Design Rules:
# - No hardcoded values in code
# - Fully config-driven execution
# - Defensive validation enforced in config_loader
# - Safe for multi-environment deployment
# =====================================================================


# =====================================================================
# Project Metadata
# =====================================================================
project:
  name: "Intelligent Demand Sensing & Autonomous Inventory Planning"
  short_name: "IDS"
  version: "1.0.0"
  environment: "local"        # local | dev | staging | prod
  timezone: "Asia/Kolkata"


# =====================================================================
# Paths Configuration
# =====================================================================
# All file-system references must originate here.
# No pipeline may define paths directly.
paths:

  data:
    raw: "data/raw"
    processed: "data/processed"
    external: "data/external"

  output:
    forecasts: "output/forecasts"
    inventory: "output/inventory"
    metrics: "output/metrics"
    plots: "output/plots"
    reports: "output/reports"
    model: "output/model"
    scenarios: "output/scenarios"

  logs: "logs"


# =====================================================================
# Logging & Reproducibility
# =====================================================================
logging:
  level: "INFO"          # DEBUG | INFO | WARNING | ERROR | CRITICAL
  log_to_file: true
  filename: "ids_project.log"

seeds:
  global_seed: 42
  propagate_to_models: true


# =====================================================================
# Data Schema & Column Normalization
# =====================================================================
data_schema:

  # -------------------------------------------------------------------
  # Sales Dataset Schema (Primary Demand Source)
  # -------------------------------------------------------------------
  sales:
    date_column: "date"
    target_column: "total_sales"

    required_columns:
      - date
      - total_sales
      - sales_open
      - sales_closed

    optional_columns:
      - is_festival
      - is_holiday
      - is_promo
      - weekday_weekend
      - day

    optional_column_policy:
      on_missing: "warn"   # warn | ignore | error

    normalize_columns: true

    rename_map:
      date: ["date"]
      total_sales: ["total_sales", "sales", "total"]
      sales_open: ["sales_open", "open_sales"]
      sales_closed: ["sales_closed", "closed_sales"]

  # -------------------------------------------------------------------
  # Calendar Dataset Schema
  # -------------------------------------------------------------------
  calendar:
    date_column: "date"

    holiday_column: "is_holiday"
    festival_column: "is_festival"
    festival_name_column: "festival_name"

    required_columns:
      - date
      - is_festival
      - is_holiday

    optional_columns:
      - festival_name
      - day
      - weekday_weekend

    optional_column_policy:
      on_missing: "warn"

    normalize_columns: true

    rename_map:
      date: ["date"]
      is_festival: ["festival", "festival_flag", "is_festival"]
      is_holiday: ["holiday", "is_holiday"]
      festival_name: ["festival_name", "fest_name"]
      weekday_weekend: ["weekday_weekend", "week_type"]
      day: ["day", "weekday", "day_of_week"]


# =====================================================================
# Ingestion Configuration
# =====================================================================
ingestion:

  # Primary demand dataset
  demand_source: "sales"

  # Global ingestion behavior
  header: true
  skip_rows: 0

  na_values:
    - ""
    - "NA"
    - "N/A"
    - "null"
    - "None"

  strict_load: true   # Fail entire pipeline if any dataset fails


  # -------------------------------------------------------------------
  # Multi-source dataset configuration
  # -------------------------------------------------------------------
  datasets:

    # -------------------------
    # CSV Source
    # -------------------------
    calendar:
      enabled: true
      source_type: csv
      file: "calendar_holidays.csv"

      csv:
        delimiter: ","
        encoding: "utf-8"

    # -------------------------
    # Excel Source (Demand)
    # -------------------------
    sales:
      enabled: true
      source_type: excel
      file: "sales_data.xlsx"

      excel:
        sheet_name: "22-24"

    # -------------------------
    # Parquet Source
    # -------------------------
    demand_history:
      enabled: false
      source_type: parquet
      file: "demand_history.parquet"

      parquet:
        engine: "pyarrow"

    # -------------------------
    # Database Source
    # -------------------------
    master_data:
      enabled: false
      source_type: database

      database:
        engine: "postgresql"

        host: "localhost"            # or "${DB_HOST}"
        port: 5432                   # or "${DB_PORT}"
        database: "inventory_db"     # or "${DB_NAME}"

        schema: "public"
        table: "product_master"

        username_env: "DB_USER"
        password_env: "DB_PASS"

        fetch_size: 50000

    # -------------------------
    # API Source
    # -------------------------
    promotions:
      enabled: false
      source_type: api

      api:
        method: "GET"
        url: "https://api.example.com/promotions"

        headers:
          authorization_env: "API_TOKEN"
          content-type: "application/json"

        params:
          region: "IN"
          active: true

        timeout_seconds: 30


# =====================================================================
# Feature Engineering
# =====================================================================
features:

  time_features:
    enabled: true
    day_of_week: true
    is_weekend: true
    month: true
    quarter: true
    is_month_start: true
    is_month_end: true

  lag_features:
    enabled: true
    lags: [1, 7, 14, 30]

  rolling_features:
    enabled: true
    windows: [7, 14, 30]

  calendar_features:
    enabled: true

  aggregation_features:
    enabled: true
    same_weekday_window: 4

  include_promotions: false

  demand_bucketing:
    method: "quantile"
    labels: ["Low", "Medium", "High"]


# =====================================================================
# Data Cleaning Rules
# =====================================================================
data_cleaning:

  sales:

    duplicate:
      unique_key: ["date"]
      strategy: "keep_last"   # keep_first | keep_last | error | none

    missing:
      numeric: "interpolate"
      categorical: "unknown"
      boolean: "mode"
      datetime: "none"

    per_column:
      total_sales: "ffill"


# =====================================================================
# Modeling Configuration
# =====================================================================
modeling:

  train_test_split:
    method: "time"
    test_days: 90

  forecast_horizon_days: 365

  models:

    linear_regression:
      enabled: true
    
    ridge:
    enabled: true

    random_forest:
      enabled: true
      params:
        n_estimators: 200
        max_depth: 10

    xgboost:
      enabled: true
      params:
        learning_rate: 0.1
        n_estimators: 150
        max_depth: 8

    lightgbm:
      enabled: true
      params:
        learning_rate: 0.05
        n_estimators: 200
        max_depth: -1

    prophet:
      enabled: false
      yearly_seasonality: true
      weekly_seasonality: true


# =====================================================================
# Hyperparameter Tuning
# =====================================================================
hyperparameter_tuning:
  enabled: true
  tune_top_n: 3
  cv_splits: 5
  n_iter: 15

  ridge:
    alpha: [0.01, 0.1, 1, 10, 50, 100, 200]

  random_forest:
    n_estimators: [100, 200, 300]
    max_depth: [5, 10, 20]

  xgboost:
    learning_rate: [0.05, 0.1]
    max_depth: [6, 8]
    n_estimators: [100, 150, 200]

  lightgbm:
    learning_rate: [0.01, 0.05]
    max_depth: [-1, 10, 20]
    n_estimators: [100, 200]


# =====================================================================
# Ensemble Configuration
# =====================================================================
ensemble:
  method: "stacking"
  enabled: true
  top_k_models: 3
  meta_model: "ridge"


# =====================================================================
# Inventory Planning
# =====================================================================
inventory:
  service_level: 0.95
  lead_time_days: 7
  demand_variability_method: "std"

  # Training / Simulation Only
  simulated_current_inventory: 500


# =====================================================================
# Forecasting Configuration
# =====================================================================
forecasting:
  enabled: true
  frequency: "D"
  start_date: "2025-03-23"
  end_date: "2025-12-15"

  rolling_summary:
    enabled: true
    window_months: 3

  output:
    include_weekly_summary: true
    include_monthly_summary: true


# =====================================================================
# LLM What-If Scenario Engine Configuration
# =====================================================================
llm:
  enabled: true

  # ---------------------------------------------------------
  # Session Management
  # ---------------------------------------------------------
  session:
    enabled: true
    auto_create_session: true
    include_timestamp_in_filename: true

  # ---------------------------------------------------------
  # Output Folder Structure (Option B - Approved)
  # ---------------------------------------------------------
  output_structure:
    use_session_subfolders: true
    scenarios_subfolder: "scenarios"
    comparisons_subfolder: "comparisons"
    store_subfolder: "store"

  # ---------------------------------------------------------
  # Scenario Persistence (JSON Store)
  # ---------------------------------------------------------
  storage_path: "output/scenarios/store/scenario_store.json"
  scenario_ttl_hours: 24

  # ---------------------------------------------------------
  # Scenario ID Formatting
  # ---------------------------------------------------------
  id_format:
    prefix: "SCN"
    include_timestamp: true
    counter_padding: 3

  # ---------------------------------------------------------
  # Runtime Mode
  # ---------------------------------------------------------
  default_mode: "stateless"   # stateless | stateful

  runtime_control:
    allow_in_production: false
    allow_in_training: true
    allow_in_ci: false

  # ---------------------------------------------------------
  # Model Configuration (LLM Provider)
  # ---------------------------------------------------------
  model_name: "gpt-4"
  provider: "openai"
  temperature: 0.2
  max_tokens: 500
  fallback_regex: true

  # ---------------------------------------------------------
  # Strict Guardrails (Enterprise Enforcement)
  # ---------------------------------------------------------
  guardrails:
    max_demand_change_pct: 50
    max_lead_time_days: 90
    service_level_range:
      min: 0.80
      max: 0.99

  # ---------------------------------------------------------
  # Comparison Engine
  # ---------------------------------------------------------
  comparison:
    enabled: true
    recompute_inventory: true
    export_markdown: true


# =====================================================================
# Execution Controls
# =====================================================================
execution:
  mode: "train"   # dev | train | prod | backfill
  save_intermediate_outputs: true
  overwrite_existing_outputs: false


# =====================================================================
# SHAP Explainability
# =====================================================================
shap:
  enabled: true
  sample_size: 500


# ==============================
# Visualization
# ==============================
visualization:
  enabled: true
  skip_in_production: true
